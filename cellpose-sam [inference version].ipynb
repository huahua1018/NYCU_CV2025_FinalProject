{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a0c033",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:14.079876Z",
     "iopub.status.busy": "2025-06-01T23:31:14.079617Z",
     "iopub.status.idle": "2025-06-01T23:31:16.916555Z",
     "shell.execute_reply": "2025-06-01T23:31:16.915598Z"
    },
    "papermill": {
     "duration": 2.842004,
     "end_time": "2025-06-01T23:31:16.918003",
     "exception": false,
     "start_time": "2025-06-01T23:31:14.075999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/cps-env/wheels/wheels\r\n",
      "Processing /kaggle/input/cps-env/wheels/wheels/cellpose-4.0.4.dev7+gfb5a6c0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/cps-env/wheels/wheels/fastremap-1.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/cps-env/wheels/wheels/fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/cps-env/wheels/wheels/roifile-2025.5.10-py3-none-any.whl\r\n",
      "Installing collected packages: fill_voids, cellpose, roifile, fastremap\r\n",
      "Successfully installed cellpose-4.0.4.dev7+gfb5a6c0 fastremap-1.16.1 fill_voids-2.0.8 roifile-2025.5.10\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index --find-links /kaggle/input/cps-env/wheels/wheels --no-deps cellpose fastremap fill_voids roifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12076749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:16.924097Z",
     "iopub.status.busy": "2025-06-01T23:31:16.923809Z",
     "iopub.status.idle": "2025-06-01T23:31:53.400719Z",
     "shell.execute_reply": "2025-06-01T23:31:53.400017Z"
    },
    "papermill": {
     "duration": 36.48322,
     "end_time": "2025-06-01T23:31:53.404046",
     "exception": false,
     "start_time": "2025-06-01T23:31:16.920826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.4.dev7+gfb5a6c0 \n",
      "platform:       \tlinux \n",
      "python version: \t3.11.11 \n",
      "torch version:  \t2.6.0+cu124! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n",
      "Loaded 1 models for ensemble.\n"
     ]
    }
   ],
   "source": [
    "from cellpose import models, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "\n",
    "ensemble_weights = [\n",
    "    #'/kaggle/input/patch4_base_bs2/pytorch/default/1/patch_epoch100_bs2_epoch_0031',\n",
    "    '/kaggle/input/cosbest/pytorch/default/3/patch_epoch100_bs2__epoch_0031',#0.339\n",
    "    #'/kaggle/input/cosbest/pytorch/default/1/patch_epoch100_bs2__epoch_0031',\n",
    "    # '/kaggle/input/cellpose-fold-weight/fold0_epoch_0032_mAP_0.3129.pth',#0.334\n",
    "    # '/kaggle/input/cellpose-fold-weight/fold1_epoch_0038_mAP_0.2929.pth',#0.335\n",
    "    # '/kaggle/input/cellpose-fold-weight/fold2_epoch_0058_mAP_0.3104.pth', #0.334\n",
    "    # '/kaggle/input/fold3-best/pytorch/default/1/fullres_fold3_epoch_0067', #0.336\n",
    "    # '/kaggle/input/cellpose-fold-weight/fold4_epoch_0047_mAP_0.2945.pth'#0.335\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "models_list = [\n",
    "    models.CellposeModel(\n",
    "        gpu=True,\n",
    "        pretrained_model=weight_path\n",
    "    )\n",
    "    for weight_path in ensemble_weights\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(models_list)} models for ensemble.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be23bd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:53.409966Z",
     "iopub.status.busy": "2025-06-01T23:31:53.409362Z",
     "iopub.status.idle": "2025-06-01T23:31:53.416603Z",
     "shell.execute_reply": "2025-06-01T23:31:53.415905Z"
    },
    "papermill": {
     "duration": 0.011429,
     "end_time": "2025-06-01T23:31:53.417837",
     "exception": false,
     "start_time": "2025-06-01T23:31:53.406408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"\n",
    "    Encode a binary mask into RLE string.\n",
    "    mask: 2D numpy array, 1=foreground, 0=background\n",
    "    returns: RLE string (\"start length\" format)\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(rle_str, shape=(520, 704)):\n",
    "    \"\"\"\n",
    "    Decode RLE string back to a binary mask.\n",
    "    rle_str: RLE string (\"start length\")\n",
    "    shape: (height, width) of output mask\n",
    "    returns: 2D numpy array mask\n",
    "    \"\"\"\n",
    "    if not isinstance(rle_str, str) or not rle_str:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    parts = rle_str.split()\n",
    "    starts = np.asarray(parts[0::2], dtype=int) - 1\n",
    "    lengths = np.asarray(parts[1::2], dtype=int)\n",
    "    mask_flat = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for s, l in zip(starts, lengths):\n",
    "        mask_flat[s:s + l] = 1\n",
    "    return mask_flat.reshape(shape)\n",
    "\n",
    "def compute_iou(mask1, mask2):\n",
    "    \"\"\"\n",
    "    Compute IoU of two binary masks.\n",
    "    mask1, mask2: 2D arrays (bool or uint8)\n",
    "    returns: IoU float\n",
    "    \"\"\"\n",
    "    m1 = mask1.astype(bool)\n",
    "    m2 = mask2.astype(bool)\n",
    "    inter = np.logical_and(m1, m2).sum()\n",
    "    union = np.logical_or(m1, m2).sum()\n",
    "    return inter / union if union > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ace32a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:53.423347Z",
     "iopub.status.busy": "2025-06-01T23:31:53.423125Z",
     "iopub.status.idle": "2025-06-01T23:31:53.442411Z",
     "shell.execute_reply": "2025-06-01T23:31:53.441862Z"
    },
    "papermill": {
     "duration": 0.023408,
     "end_time": "2025-06-01T23:31:53.443520",
     "exception": false,
     "start_time": "2025-06-01T23:31:53.420112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pycocotools.mask\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def maskwise_nms(masks, iou_thresh=0.6):\n",
    "    \"\"\"\n",
    "    Perform mask-level Non-Maximum Suppression (NMS).\n",
    "    masks: np.ndarray of shape (K, H, W) containing binary masks\n",
    "    iou_thresh: IoU threshold for suppression\n",
    "    returns: np.ndarray of shape (M, H, W) with NMS‐filtered masks\n",
    "    \"\"\"\n",
    "    keep_indices = []\n",
    "    K = masks.shape[0]\n",
    "    for i in range(K):\n",
    "        if i in keep_indices:\n",
    "            continue\n",
    "        m1 = masks[i].astype(bool)\n",
    "        suppress = False\n",
    "        for j in keep_indices:\n",
    "            m2 = masks[j].astype(bool)\n",
    "            # compute IoU\n",
    "            inter = np.logical_and(m1, m2).sum()\n",
    "            union = np.logical_or(m1, m2).sum()\n",
    "            iou = inter / union if union > 0 else 0.0\n",
    "            if iou > iou_thresh:\n",
    "                suppress = True\n",
    "                break\n",
    "        if not suppress:\n",
    "            keep_indices.append(i)\n",
    "    if not keep_indices:\n",
    "        return np.zeros((0, masks.shape[1], masks.shape[2]), dtype=np.uint8)\n",
    "    return masks[keep_indices]\n",
    "\n",
    "\n",
    "def instmap_to_masks_boxes(inst_map):\n",
    "    \"\"\"\n",
    "    Convert a 2D instance label map into binary masks and bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        inst_map (np.ndarray): shape = (H, W), dense instance map\n",
    "                              0 = background, 1, 2, 3... = instance labels.\n",
    "    \n",
    "    Returns:\n",
    "        masks (np.ndarray): shape = (K, H, W) of binary masks.\n",
    "        boxes (np.ndarray): shape = (K, 6), each row = [x0, y0, x1, y1, area, 0.0].\n",
    "                            Returns (None, None) if no instances found.\n",
    "    \"\"\"\n",
    "    masks, boxes = [], []\n",
    "    for lab in np.unique(inst_map)[1:]:\n",
    "        m = (inst_map == lab).astype(np.uint8)\n",
    "        ys, xs = np.where(m)\n",
    "        if ys.size == 0:\n",
    "            continue\n",
    "        area = int(m.sum())\n",
    "        masks.append(m)\n",
    "        boxes.append([xs.min(), ys.min(), xs.max(), ys.max(), area, 0.0])\n",
    "    if not masks:\n",
    "        return None, None\n",
    "    return np.stack(masks, axis=0), np.array(boxes, dtype=float)\n",
    "\n",
    "\n",
    "def weighted_mask_fusion_nmw(masks, boxes, scores, iou_thr=0.15, score_coef=0.8):\n",
    "    \"\"\"\n",
    "    Weighted NMW (Non-Maximum Weighted) fusion:\n",
    "      1. Compute pairwise IoU for all masks -> ious (N×N).\n",
    "      2. Treat masks with IoU > iou_thr as the same cluster.\n",
    "      3. For each cluster, multiply each mask's score by score_coef, then normalize -> weights.\n",
    "      4. Compute pixel-wise weighted sum across masks in cluster -> soft_map.\n",
    "      5. Threshold soft_map at 0.5 -> fused mask; if all < 0.5, pick the highest-score original mask.\n",
    "\n",
    "    Args:\n",
    "        masks (np.ndarray): shape = (N, H, W), list of binary masks.\n",
    "        boxes (np.ndarray): shape = (N, 6), each row = [x0, y0, x1, y1, area, dummy_score].\n",
    "        scores (np.ndarray): shape = (N,), float scores for each mask.\n",
    "        iou_thr (float): IoU threshold to form clusters.\n",
    "        score_coef (float): coefficient < 1 to scale scores before normalization.\n",
    "\n",
    "    Returns:\n",
    "        fused_masks (np.ndarray): shape = (M, H, W), list of fused binary masks.\n",
    "        fused_boxes (np.ndarray): shape = (M, 6), list of bounding boxes for fused masks.\n",
    "    \"\"\"\n",
    "    N = masks.shape[0]\n",
    "    if N == 0:\n",
    "        return (\n",
    "            np.zeros((0, masks.shape[1], masks.shape[2]), dtype=np.uint8),\n",
    "            np.zeros((0, 6), dtype=float),\n",
    "        )\n",
    "\n",
    "    rles = [pycocotools.mask.encode(np.asfortranarray(m)) for m in masks]\n",
    "    ious = pycocotools.mask.iou(rles, rles, [0] * N)\n",
    "    used = set()\n",
    "    fused_masks, fused_boxes = [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        if i in used:\n",
    "            continue\n",
    "        group = [i]\n",
    "        for j in range(i + 1, N):\n",
    "            if ious[i, j] > iou_thr:\n",
    "                group.append(j)\n",
    "        used.update(group)\n",
    "\n",
    "        sub_masks = masks[group]\n",
    "        sub_boxes = boxes[group]\n",
    "        sub_scores = scores[group].astype(float) * score_coef\n",
    "\n",
    "        if len(group) == 1:\n",
    "            fused_masks.append(sub_masks[0])\n",
    "            fused_boxes.append(sub_boxes[0])\n",
    "            continue\n",
    "\n",
    "        weights = sub_scores / sub_scores.sum()\n",
    "        soft_map = np.tensordot(weights, sub_masks, axes=(0, 0))\n",
    "        bin_mask = (soft_map >= 0.5).astype(np.uint8)\n",
    "\n",
    "        ys, xs = np.where(bin_mask)\n",
    "        if ys.size == 0:\n",
    "            best_idx = group[np.argmax(sub_scores)]\n",
    "            bin_mask = masks[best_idx]\n",
    "            ys, xs = np.where(bin_mask)\n",
    "            fused_masks.append(bin_mask)\n",
    "            fused_boxes.append([\n",
    "                xs.min(), ys.min(), xs.max(), ys.max(),\n",
    "                int(bin_mask.sum()), 0.0\n",
    "            ])\n",
    "        else:\n",
    "            fused_masks.append(bin_mask)\n",
    "            fused_boxes.append([\n",
    "                xs.min(), ys.min(), xs.max(), ys.max(),\n",
    "                int(bin_mask.sum()), 0.0\n",
    "            ])\n",
    "\n",
    "    if not fused_masks:\n",
    "        return (\n",
    "            np.zeros((0, masks.shape[1], masks.shape[2]), dtype=np.uint8),\n",
    "            np.zeros((0, 6), dtype=float),\n",
    "        )\n",
    "    return np.stack(fused_masks, axis=0), np.array(fused_boxes, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0fa2e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:53.449080Z",
     "iopub.status.busy": "2025-06-01T23:31:53.448831Z",
     "iopub.status.idle": "2025-06-01T23:31:53.456113Z",
     "shell.execute_reply": "2025-06-01T23:31:53.455602Z"
    },
    "papermill": {
     "duration": 0.011465,
     "end_time": "2025-06-01T23:31:53.457314",
     "exception": false,
     "start_time": "2025-06-01T23:31:53.445849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def tta_predict_probability_and_flows(model, image, image_id):\n",
    "    \"\"\"\n",
    "    Use TTA (original + horizontal flip) to compute averaged probability and flow maps.\n",
    "\n",
    "    Args:\n",
    "        model: CellposeModel instance.\n",
    "        image: numpy array of shape (H, W, 3).\n",
    "        image_id: string identifier (not used here).\n",
    "\n",
    "    Returns:\n",
    "        averaged_prob_map: numpy array of shape (H, W), dtype float32.\n",
    "        averaged_dp_map: numpy array of shape (2, H, W), dtype float32.\n",
    "    \"\"\"\n",
    "    H, W = image.shape[:2]\n",
    "\n",
    "    # Two augmentations: original and horizontally flipped\n",
    "    aug_images = [\n",
    "        image,\n",
    "        np.flip(image, axis=1),\n",
    "    ]\n",
    "\n",
    "    # Inverse transforms to revert flips\n",
    "    inverse_ops_prob = [\n",
    "        lambda x: x,\n",
    "        lambda x: np.flip(x, axis=1),\n",
    "    ]\n",
    "    inverse_ops_dp = [\n",
    "        lambda dp: dp,\n",
    "        lambda dp: np.stack([\n",
    "            np.flip(dp[0], axis=1),\n",
    "            -np.flip(dp[1], axis=1),\n",
    "        ], axis=0),\n",
    "    ]\n",
    "\n",
    "    all_prob_maps = []\n",
    "    all_dp_maps = []\n",
    "\n",
    "    for aug_idx, aug_img in enumerate(aug_images):\n",
    "        # Run model.eval on augmented image (no mask decoding)\n",
    "        _, eval_flows, _ = model.eval(aug_img, compute_masks=False)\n",
    "        pred_dp_map_raw = eval_flows[1].astype(np.float32)   # shape = (2, h', w')\n",
    "        pred_prob_map_raw = eval_flows[2].astype(np.float32) # shape = (h', w')\n",
    "\n",
    "        # Apply inverse transform to flip results back\n",
    "        prob_aug = inverse_ops_prob[aug_idx](pred_prob_map_raw)\n",
    "        dp_aug = inverse_ops_dp[aug_idx](pred_dp_map_raw)\n",
    "\n",
    "        # Resize probability map if shape differs\n",
    "        if prob_aug.shape[:2] != (H, W):\n",
    "            prob_aug = cv2.resize(\n",
    "                prob_aug, (W, H), interpolation=cv2.INTER_LINEAR\n",
    "            )\n",
    "\n",
    "        # Resize flow map if shape differs\n",
    "        if dp_aug.shape[1:] != (H, W):\n",
    "            dp_x = cv2.resize(\n",
    "                dp_aug[0], (W, H), interpolation=cv2.INTER_LINEAR\n",
    "            )\n",
    "            dp_y = cv2.resize(\n",
    "                dp_aug[1], (W, H), interpolation=cv2.INTER_LINEAR\n",
    "            )\n",
    "            dp_aug = np.stack([dp_x, dp_y], axis=0)\n",
    "\n",
    "        all_prob_maps.append(prob_aug)\n",
    "        all_dp_maps.append(dp_aug)\n",
    "\n",
    "    # Compute average over augmentations\n",
    "    averaged_prob_map = np.mean(\n",
    "        np.stack(all_prob_maps, axis=0), axis=0\n",
    "    )\n",
    "    averaged_dp_map = np.mean(\n",
    "        np.stack(all_dp_maps, axis=0), axis=0\n",
    "    )\n",
    "\n",
    "    return averaged_prob_map, averaged_dp_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bdccb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T23:31:53.462674Z",
     "iopub.status.busy": "2025-06-01T23:31:53.462447Z",
     "iopub.status.idle": "2025-06-01T23:32:17.924694Z",
     "shell.execute_reply": "2025-06-01T23:32:17.923796Z"
    },
    "papermill": {
     "duration": 24.466203,
     "end_time": "2025-06-01T23:32:17.925775",
     "exception": false,
     "start_time": "2025-06-01T23:31:53.459572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 3/3 [00:24<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are more than one instance in the images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking pixel overlaps: 100%|██████████| 3/3 [00:00<00:00, 153.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have no overlapping pixels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference + Ensemble (multi-model TTA) + NMW post-processing\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import skimage.io as io\n",
    "from cellpose import dynamics, models, core, io as cpio, metrics\n",
    "import cv2\n",
    "\n",
    "# parameters configs\n",
    "decode_flow_th = 0.4\n",
    "iou_thr_nmw = 0.45\n",
    "score_coef = 0.8\n",
    "min_size = 75\n",
    "# corrupt = True\n",
    "# cell_type = 0\n",
    "\n",
    "test_dir = Path('/kaggle/input/sartorius-cell-instance-segmentation/test')\n",
    "test_files = sorted(f for f in test_dir.iterdir() if f.suffix == '.png')\n",
    "\n",
    "submission_data = []\n",
    "for img_path in tqdm(test_files, desc=\"Inference\"):\n",
    "    img_id = img_path.stem\n",
    "    img = io.imread(str(img_path))\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    all_masks, all_boxes, all_scores = [], [], []\n",
    "    for mdl in models_list:\n",
    "        # TTA -> get avg_prob_map, avg_dp_map\n",
    "        avg_prob_map, avg_dp_map = tta_predict_probability_and_flows(mdl, img, \"\")\n",
    "        # decode dense instance map\n",
    "        combined_mask = dynamics.resize_and_compute_masks(\n",
    "            avg_dp_map, avg_prob_map,\n",
    "            cellprob_threshold=0.0, flow_threshold=decode_flow_th,\n",
    "            min_size=20, resize=(H, W), device=mdl.device\n",
    "        )\n",
    "        if combined_mask.max() == 0:\n",
    "            continue\n",
    "\n",
    "        m_bin, bxs = instmap_to_masks_boxes(combined_mask)\n",
    "        if m_bin is None:\n",
    "            continue\n",
    "\n",
    "        # compute instance scores\n",
    "        inst_scores = []\n",
    "        for mask_k in m_bin:\n",
    "            mbool = mask_k.astype(bool)\n",
    "            inst_scores.append(float(avg_prob_map[mbool].mean()) if mbool.sum() > 0 else 0.0)\n",
    "        inst_scores = np.array(inst_scores)\n",
    "\n",
    "        all_masks.append(m_bin)\n",
    "        all_boxes.append(bxs)\n",
    "        all_scores.append(inst_scores)\n",
    "\n",
    "    if not all_masks:\n",
    "        submission_data.append({'id': img_id, 'predicted': ''})\n",
    "        continue\n",
    "\n",
    "    masks_concat = np.concatenate(all_masks, axis=0)\n",
    "    boxes_concat = np.concatenate(all_boxes, axis=0)\n",
    "    scores_concat = np.concatenate(all_scores, axis=0)\n",
    "\n",
    "    # Weighted Mask Fusion (NMW)\n",
    "    fused_masks, fused_boxes = weighted_mask_fusion_nmw(\n",
    "        masks_concat, boxes_concat, scores_concat,\n",
    "        iou_thr=iou_thr_nmw, score_coef=score_coef\n",
    "    )\n",
    "\n",
    "    # filter small masks\n",
    "    if fused_masks.shape[0] > 0:\n",
    "        areas = fused_masks.sum(axis=(1, 2))\n",
    "        keep = np.where(areas > min_size)[0]\n",
    "        fused_masks = fused_masks[keep]\n",
    "        fused_boxes = fused_boxes[keep]\n",
    "\n",
    "    if fused_masks.shape[0] > 0:\n",
    "        fused_masks = maskwise_nms(fused_masks, iou_thresh=0.6)\n",
    "\n",
    "\n",
    "    \n",
    "    # reconstruct final instance map & encode to RLE\n",
    "    canvas = np.zeros((H, W), dtype=np.int32)\n",
    "    for m in fused_masks:\n",
    "        canvas[m.astype(bool)] = canvas.max() + 1\n",
    "\n",
    "    if canvas.max() > 0:\n",
    "        for inst_id in np.unique(canvas)[1:]:\n",
    "            binary_mask = (canvas == inst_id).astype(np.uint8)\n",
    "            rle = rle_encode(binary_mask)\n",
    "            submission_data.append({'id': img_id, 'predicted': rle})\n",
    "    else:\n",
    "        submission_data.append({'id': img_id, 'predicted': ''})\n",
    "\n",
    "# assemble submission DataFrame\n",
    "submission_df = pd.DataFrame(submission_data, columns=['id', 'predicted'])\n",
    "all_test_ids = [f.stem for f in test_files]\n",
    "missing_ids = set(all_test_ids) - set(submission_df['id'].unique())\n",
    "for img_id in missing_ids:\n",
    "    submission_df = pd.concat(\n",
    "        [submission_df, pd.DataFrame([{'id': img_id, 'predicted': ''}])],\n",
    "        ignore_index=True\n",
    "    )\n",
    "submission_df = submission_df.sort_values(by='id').reset_index(drop=True)\n",
    "\n",
    "# check duplicates\n",
    "if submission_df.duplicated(subset=['id'], keep=False).any():\n",
    "    print(\"There are more than one instance in the images.\")\n",
    "\n",
    "# check pixel overlaps\n",
    "rle_dict = defaultdict(list)\n",
    "for img_id, rle_text in zip(submission_df['id'], submission_df['predicted']):\n",
    "    if isinstance(rle_text, str) and rle_text.strip():\n",
    "        rle_dict[img_id].append(rle_text)\n",
    "\n",
    "overlap_count = 0\n",
    "for img_id, rles in tqdm(rle_dict.items(), desc=\"Checking pixel overlaps\"):\n",
    "    mask_sum = np.zeros((520, 704), dtype=np.uint8)\n",
    "    for rle_text in rles:\n",
    "        mask = rle_decode(rle_text, (520, 704))\n",
    "        mask_sum += mask\n",
    "    if (mask_sum > 1).any():\n",
    "        print(f\"Image {img_id} has overlapping pixels.\")\n",
    "        overlap_count += 1\n",
    "\n",
    "if overlap_count == 0:\n",
    "    print(\"All images have no overlapping pixels.\")\n",
    "else:\n",
    "    print(f\"{overlap_count} images have overlapping issues, please review.\")\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2750748,
     "sourceId": 30201,
     "sourceType": "competition"
    },
    {
     "datasetId": 7447888,
     "sourceId": 11860693,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7564337,
     "sourceId": 12023131,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 350468,
     "modelInstanceId": 329622,
     "sourceId": 403087,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 353681,
     "modelInstanceId": 332753,
     "sourceId": 420984,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.280546,
   "end_time": "2025-06-01T23:32:21.176361",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-01T23:31:09.895815",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
